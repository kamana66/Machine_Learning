{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c70ec3b7-ba7f-4d4c-ba40-469ec0332a88",
   "metadata": {},
   "source": [
    "## Naive Bayes Algorithm - Classification of Algorithm\n",
    "- Based on **Bayes's theorem** of conditional probability\n",
    "- Calculate the probability of each test point to be in either of classes, given that the features that determine the class are given.\n",
    "- P(0/x1,x2,x3) and P(1/x1,x2,x3) is calculated, where 0 and 1 are classificcation. x1,x2,x3 are features\n",
    "- This algorithm assumes \n",
    "    - all classes are independent, while its not that true always. However, despite going wrong on basic logic, its still a very strong algorithm.\n",
    "    - Sequence doesn't matter, while its not true. Like the sequence of words in a sentence do matter for meaning of sentence.\n",
    "- Eg: In NLP, this is used to understand the tone of text like, 'If this word is present in the sentence, what class it belongs to?'\n",
    "- Widely used in HAM-SPAM classification\n",
    "- Very fast algorithm as it simply calculates probability based on features. Very strong results despite assumptions that serve as basis of algorithm are wrong. \n",
    "- Technically it processes words and language, so it may be thought as a part of NLP. But since it doens't understand semantics and sentiments of language, it can't handle language processing on its own.\n",
    "### 3 Types of Naive Bayes in Scikit Learn\n",
    "__Gaussian__\n",
    "- It is used in classification and it assumes that features follow a normal distribution.\n",
    "\n",
    "__Multinominal__\n",
    "- It is used for discrete counts. For eg., let's say we have a text cLassification problem. Here we consider Bernoulli trails which is one step further and instead of \"word occuring in the document\", we have \"count how often word occurs in the document\" you can think of it as \"number of times outcome number_x is observed over n trails\".\n",
    "\n",
    "__Bernoulli__\n",
    "- The binomial model is useful if your feature vectors are binary (ie., Zeroes and One). One application would be text classification with 'bag of words' model where the 1s and 0s are \"words occur in the document\" and \"word does not occur in the document\" respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a7f0e25-a282-4a4e-91cf-8ebee6771777",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               text\n",
       "0   ham  I've been searching for the right words to tha...\n",
       "1  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3   ham  Even my brother is not like to speak with me. ...\n",
       "4   ham               I HAVE A DATE ON SUNDAY WITH WILL!!!"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "df = pd.read_csv(\"spam.tsv\",sep='\\t',names=['Class','text'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e304ca1a-4f5a-416b-be8f-507c2f5eaba5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type                                              email\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The csv file being read\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "df1 = pd.read_csv(\"spam.csv\",encoding='latin1')    #encoding is specified as latin1 because text contains non-unicode characters\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6caf3f4e-285e-44b6-a98f-a6d540f314c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5567, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "521eb264-c7e0-459b-bb90-7dfc335a266e",
   "metadata": {},
   "source": [
    "## Text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "362dafd0-4085-4511-9f71-c8a2050939bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['Class']=='spam','Class'] = 1\n",
    "df.loc[df['Class']=='ham','Class'] = 0\n",
    "y = df['Class'].values #defining target\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a2d5ed4-0ede-4bf0-b228-f747a8adf545",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Strings are sensitive to case and punctuation. So when dealing with strings, we remove punctuations and convert case\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b16d1a62-1097-400f-8e2c-6bca2141a239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Why is it important to remove punctuation?\n",
    "\n",
    "\"This message is spam\" == \"This message is spam.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "569e0f5c-5522-42af-94cd-494472221d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Animals are dfd'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_punc(text):\n",
    "    return \"\".join(char for char in text if char not in string.punctuation)\n",
    "remove_punc('Animals are ,dfd/.,/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1b28c01-5c20-4efd-bd4e-757eb612e0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Class</th>\n",
       "      <th>text</th>\n",
       "      <th>cln_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I've been searching for the right words to tha...</td>\n",
       "      <td>ive been searching for the right words to than...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in 2 a wkly comp to win fa cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>I HAVE A DATE ON SUNDAY WITH WILL!!!</td>\n",
       "      <td>i have a date on sunday with will</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Class                                               text  \\\n",
       "0     0  I've been searching for the right words to tha...   \n",
       "1     1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "2     0  Nah I don't think he goes to usf, he lives aro...   \n",
       "3     0  Even my brother is not like to speak with me. ...   \n",
       "4     0               I HAVE A DATE ON SUNDAY WITH WILL!!!   \n",
       "\n",
       "                                             cln_txt  \n",
       "0  ive been searching for the right words to than...  \n",
       "1  free entry in 2 a wkly comp to win fa cup fina...  \n",
       "2  nah i dont think he goes to usf he lives aroun...  \n",
       "3  even my brother is not like to speak with me t...  \n",
       "4                  i have a date on sunday with will  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply this function using 'apply' command or use a for loop\n",
    "df['cln_txt'] = df['text'].apply(lambda x: remove_punc(x).lower())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2b807d5-30a2-400c-af26-d68c4ac430c2",
   "metadata": {},
   "source": [
    "- Tokenization (process of converting the normal text strings in to a list of tokens(also known as lemmas)).\n",
    "- Now we need to convert each of those messages into a vector the SciKit Learn's algorithm models can work with and machine learning model which we will gonig to use can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae08f016-c79a-4e9c-a156-058df134f57e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5567"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf5be56f-1e40-4fbd-a3dc-571ec74dd7be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72c36ca3-2de8-4d0e-a418-79e104585272",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "cv=CountVectorizer(stop_words='english')\n",
    "# Countvectorizer is a method to convert text to numerical data.\n",
    "#specifying stop_words='english': Stops adding 'the','a' kind of words in the bag of words, \n",
    "#which might end up adding weightages to those words and their probabilities\n",
    "x = df['cln_txt']\n",
    "x_vec1 = cv.fit_transform(x)\n",
    "x_vec = x_vec1.toarray()    #vectorising the words and making it an array.\n",
    "y = y.astype('int8')  #Type casting y to integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45e28434-fd04-4f79-bd00-fb803e44be02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'scipy.sparse._csr.csr_matrix'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_vec1), type(x_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef7f5a7f-5a4d-4e73-a9a2-a9e8170babb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5567, 9270)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "98d2e4a3-67f3-4a06-9978-52ddd06433ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d879c26-2ea7-4ac1-a38b-f3d805b58546",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(x_vec,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb07fc9b-1f66-4969-8c4f-625107311e4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4453 1114\n"
     ]
    }
   ],
   "source": [
    "print(len(x_train),len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "99f85e89-e7c6-428e-a212-66267afad605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1], dtype=int8)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB   #Bernouli's NB is ideal\n",
    "nb = MultinomialNB()  #Creating instance\n",
    "nb.fit(x_train,y_train)\n",
    "y_pred = nb.predict(x_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4215ebb-ec70-49ac-912d-b43af6147040",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "0    4821\n",
       "1     746\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Class.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "02f8020b-7b81-4d31-8440-8717f31e18a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99       969\n",
      "           1       0.88      0.96      0.92       145\n",
      "\n",
      "    accuracy                           0.98      1114\n",
      "   macro avg       0.94      0.97      0.95      1114\n",
      "weighted avg       0.98      0.98      0.98      1114\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac5c1fe8-7015-43ed-b608-933126870c99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a message:  you have won a lottery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text= input('Enter a message: ')\n",
    "#txt = np.array(text)\n",
    "txt_vec = cv.transform([text])\n",
    "_pred = nb.predict(txt_vec)\n",
    "if _pred == 0:\n",
    "    print('ham')\n",
    "else:\n",
    "    print('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f936485e-02ec-41b3-9963-ada968a1b502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter a message:  YOu win a lottery\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text= input('Enter a message: ')\n",
    "#txt = np.array(text)\n",
    "txt_vec = cv.transform([text])\n",
    "_pred = nb.predict(txt_vec)\n",
    "if _pred == 0:\n",
    "    print('ham')\n",
    "else:\n",
    "    print('spam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccc48fc-a9f7-40c4-a5c5-3b51d991f33a",
   "metadata": {},
   "source": [
    "## BAG OF WORDS\n",
    "We cannot pass text directly to train our models in Natural Language Processing, thus we need to convert it into numbers, which machine can understand and can perform the required modelling on it\n",
    "### TF-IDF approach\n",
    "In **BOW approach** we saw so far, all the words in the text are treated equally important. There is no notion of some words in the document being more important than others. TF-IDF addresses this issue. It aims to quantify the importance of a given word relative to other words in the document and in the\n",
    "\n",
    "\n",
    "<font color=darkviolet>  **Term Frequency (tf)** </font>\n",
    "TF: Term Frequency, which measures how frequently a term occurs in a document. Since every document is different in length, it is possible that a term would appear much more times in long documents than shorter ones. Thus, the term frequency is often divided by the document length (aka. the total number of terms in the document) as a way of normalization:\n",
    "\n",
    "TF(t) = (Number of times term 't' appears in a document) / (Total number of terms in the document).\n",
    "\n",
    "\n",
    "\n",
    "<font color=darkviolet>  **Inverse Document Frequency (idf)** </font>\n",
    "              It measures how important a term is. While computing TF, all terms are considered equally important. However it is known that certain terms, such as \"is\", \"of\", and \"that\", may appear a lot of times but have little importance. Thus we need to weigh down the frequent terms while scale up the rare ones, by computing the following:\n",
    "\n",
    "IDF(t) = log_e(Total number of documents / Number of documents with term t in it).corpus. It was commonly used representation scheme for information retrieval systems, for extracting relevant documents from a corpus for given text query.\n",
    "\n",
    "\n",
    "\n",
    "__Let's see an example:__\n",
    "\n",
    "Consider a document containing 100 words wherein the word cat appears 3 times.\n",
    "\n",
    "The term frequency (i.e., tf) for cat is then (3 / 100) = 0.03.\n",
    "\n",
    "Now, assume we have 10 million documents and the word cat appears in one thousand of these.\n",
    "\n",
    "Then, the inverse document frequency (i.e., idf) is calculated as log(10,000,000 / 1,000) = 4.\n",
    "\n",
    "Thus, the Tf-idf weight is the product of these quantities: 0.03 * 4 = 0.12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3b10ff9a-c9f7-4ec8-ad23-c5618e2cd76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## text preprocessing and feature vectorizer\n",
    "# To extract features from a document of words, we import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "x = df['cln_txt']\n",
    "tf=TfidfVectorizer() ## object creation\n",
    "X=tf.fit_transform(x) ## fitting and transforming the data into vector\n",
    "y = y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9ccdb860-aa31-48a0-9ce2-145a3ff6f07e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['008704050406', '0089my', '0121', ..., 'zyada', 'üll', '〨ud'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print feature names selected from the raw documents\n",
    "#tf.get_feature_names()\n",
    "tf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b2fa7a1-0b04-4066-8860-a638e17d6f86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9537"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## number of features created\n",
    "len(tf.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dedb71e-8f48-4332-9d71-e9ff6b46df57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting the feature vectors (TFIDF arrays are not just as sparse as CV method, so they will be stored as native np arrays. toarray() commmand wont be needed)\n",
    "X=X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a05047be-87e3-4dea-a2db-d16c4f856992",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating training and testing\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1bdba9ab-809c-4aab-bf2b-9c4fa8db30c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model creation\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "## model object creation\n",
    "nb=BernoulliNB(alpha=0.01)\n",
    "\n",
    "## fitting the model\n",
    "nb.fit(X_train,y_train)\n",
    "\n",
    "## getting the prediction\n",
    "y_hat=nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "075e31c8-696e-48cd-8fbb-aa43eb56ba25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1206\n",
      "           1       0.96      0.96      0.96       186\n",
      "\n",
      "    accuracy                           0.99      1392\n",
      "   macro avg       0.98      0.98      0.98      1392\n",
      "weighted avg       0.99      0.99      0.99      1392\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the model\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e910d589-1c73-416b-b789-1078d39b810e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
